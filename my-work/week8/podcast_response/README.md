### Podcast Response - Week 8
- [*Right to be Forgotten*](https://www.wnycstudios.org/podcasts/radiolab/articles/radiolab-right-be-forgotten) by Radiolab.
- [*The End of Privacy as We Know It?*](https://www.nytimes.com/2020/02/10/podcasts/the-daily/facial-recognition-surveillance.html) by The Daily from The New York Times.

#### [Right to be Forgotten](https://www.wnycstudios.org/podcasts/radiolab/articles/radiolab-right-be-forgotten)
The Internet works upon an infrastructure of unprecedented intricacy as a publishing platform. There are multiple stakeholders intertwined with a single result from a Google search, and the dilemma derives inside the grey area of transparency and privacy. The transparency is realized and encoded by everlasting bits transcending the physical form of information. And the privacy in the digital age can only be preserved by artificial rules out of ethics and laws, rather than technical limit. Once public records are out, they are out forever technically and they probably should not be taken down, as some may agree. Nothing can stop people with interest from constantly scraping. And yet, taking down public information can be troublesome for less technically competent people concerned by subject.

I think what should be changed is the inclusiveness of our society, which is difficult but the most robust solution to the technical invasion into our life. Emerging technologies will always transcend human capability and change our ways of life, as is how the current capitalist school of thought works. Yesterday, they were the search engine and social media. Today, they are data-mining and direct marketing. Tomorrow, they might be a surveillance-driven omnipresent big brother or whatever. Greater power comes with greater responsibility, and in a sense, we all carry the same weight as Mark Zuckerburg. Even if the European GDPR and other legal regulations on the technology abuse give us hope in the narrative of humanity hitting the brake of technology, they come late with no ease. Why not think about a society that forgets and forgives *because* the technical infrastructure remembers and shows indifference? The ones haunted by digital records of their old days ought to be given a way out from others' discrimination as a new social contract which we should all be on board with.

I have seen similar discussions on [Tianyancha](https://www.tianyancha.com/) and other similar services that scrape, synthesize, and visualize public Chinese enterprise information. The service provides an overview of lawsuits related to individuals and companies. Many people use it as a reference to evaluate risks, whereas not all company lawsuits are related to the actual business - many of them are dispute resolution of work accidents. The number of lawsuits would stack up quickly if certain positions in the company involve risky labor, which gives a disadvantage in trust when being researched on these platforms. Surely I am not saying that legal records of a company should be hidden, but the connotation of data transparency changes with the way of presenting data.

#### [*The End of Privacy as We Know It?*](https://www.nytimes.com/2020/02/10/podcasts/the-daily/facial-recognition-surveillance.html)
How ClearView works and how well it works is just astonishing. No one is prepared for a future where the digital traces of us can be easily correlated and retrieved. 

"No China, no Russia, or any like that." CEO of the company Ton-That says when asked about their ideal buyers of the technology. Despite being loosely put, it sounds like a claim against authoritarian governments. However, practically speaking, the reason why China wouldn't buy such a service might simply be that the government already has one. The Chinese version might come even more powerful based on mandatory supports from tech companies.

In law enforcement, the benefits of such systems are obvious and the position is rather clear. ClearView stays a third party agency to help gather investigative clues and forensic evidence that would stay valid even if found through other means. As for the risks, or risky ambiguities as I prefer, it sits alongside with any other data mining approaches. To what extent should we allow such disturbing technology for the sake of convenience or even safety? Should we cut it off or should we review related disputes case by case before we draw the legal conclusion? Can legal actions possibly exhaust every worst-case scenario, and is there an end?

Here is one of the infinite problematic scenarios I am thinking of. If ClearView keeps its repository of scraped social media, I am still identifiable through data I have already deleted online. The photo that sells me out could be posted by an account that no longer exists. If in a legal situation, could the owner of the photo still be accountable as a witness? I would love to say that let's delete outdated data for the sake of privacy, but it also reduces the efficiency and effectiveness of the service. Or is privacy still a thing if we allow such service in the first place? The best scenario of adoption I can think of would be requiring strictly for a license of qualification and justice of use, and we hope for the best.